2020-01-07 21:53:53,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-01-07 21:53:53,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-01-07 21:53:54,544 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-01-07 21:53:54,705 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-01-07 21:53:54,705 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-01-07 21:53:54,716 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-01-07 21:53:54,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2020-01-07 21:53:54,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-01-07 21:53:54,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-01-07 21:53:54,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-01-07 21:53:54,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-01-07 21:53:55,074 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-01-07 21:53:55,085 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-01-07 21:53:55,105 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-01-07 21:53:55,124 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-01-07 21:53:55,127 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-01-07 21:53:55,128 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-01-07 21:53:55,129 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-01-07 21:53:55,166 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45033
2020-01-07 21:53:55,167 INFO org.mortbay.log: jetty-6.1.26
2020-01-07 21:53:55,967 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45033
2020-01-07 21:53:56,343 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-01-07 21:53:56,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-01-07 21:53:56,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-01-07 21:53:56,562 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-01-07 21:53:56,596 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-01-07 21:53:56,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-01-07 21:53:56,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-01-07 21:53:56,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-01-07 21:53:56,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-01-07 21:53:56,818 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-01-07 21:53:56,831 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-01-07 21:53:57,888 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 63@slave2
2020-01-07 21:53:57,892 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1867106961-172.18.0.2-1578405220772
2020-01-07 21:53:57,892 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-01-07 21:53:57,992 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1867106961-172.18.0.2-1578405220772
2020-01-07 21:53:57,993 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1867106961-172.18.0.2-1578405220772
2020-01-07 21:53:57,995 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1867106961-172.18.0.2-1578405220772 is not formatted for BP-1867106961-172.18.0.2-1578405220772
2020-01-07 21:53:57,995 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-01-07 21:53:57,996 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1867106961-172.18.0.2-1578405220772 directory /tmp/hadoop/dfs/data/current/BP-1867106961-172.18.0.2-1578405220772/current
2020-01-07 21:53:58,000 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-01-07 21:53:58,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1500497699;bpid=BP-1867106961-172.18.0.2-1578405220772;lv=-56;nsInfo=lv=-63;cid=CID-652c6a67-0593-45df-a887-b603dda67864;nsid=1500497699;c=0;bpid=BP-1867106961-172.18.0.2-1578405220772;dnuuid=null
2020-01-07 21:53:58,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID c36601a6-67c6-4070-a520-005665f1895c
2020-01-07 21:53:58,130 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-07fbbd12-8c32-488b-943d-94a7c7f7e4d6
2020-01-07 21:53:58,131 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-01-07 21:53:58,137 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-01-07 21:53:58,138 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1867106961-172.18.0.2-1578405220772
2020-01-07 21:53:58,141 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1867106961-172.18.0.2-1578405220772 on volume /tmp/hadoop/dfs/data/current...
2020-01-07 21:53:58,250 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1867106961-172.18.0.2-1578405220772 on /tmp/hadoop/dfs/data/current: 108ms
2020-01-07 21:53:58,251 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1867106961-172.18.0.2-1578405220772: 112ms
2020-01-07 21:53:58,252 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1867106961-172.18.0.2-1578405220772 on volume /tmp/hadoop/dfs/data/current...
2020-01-07 21:53:58,253 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1867106961-172.18.0.2-1578405220772 on volume /tmp/hadoop/dfs/data/current: 0ms
2020-01-07 21:53:58,254 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 2ms
2020-01-07 21:53:58,544 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1867106961-172.18.0.2-1578405220772 on volume /tmp/hadoop/dfs/data
2020-01-07 21:53:58,552 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-07fbbd12-8c32-488b-943d-94a7c7f7e4d6): finished scanning block pool BP-1867106961-172.18.0.2-1578405220772
2020-01-07 21:53:58,583 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1578425748583 with interval 21600000
2020-01-07 21:53:58,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1867106961-172.18.0.2-1578405220772 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-01-07 21:53:58,674 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-07fbbd12-8c32-488b-943d-94a7c7f7e4d6): no suitable block pools found to scan.  Waiting 1814399870 ms.
2020-01-07 21:53:58,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1867106961-172.18.0.2-1578405220772 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-01-07 21:53:58,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-01-07 21:53:58,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1867106961-172.18.0.2-1578405220772 (Datanode Uuid c36601a6-67c6-4070-a520-005665f1895c) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-01-07 21:53:58,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1867106961-172.18.0.2-1578405220772 (Datanode Uuid c36601a6-67c6-4070-a520-005665f1895c) service to master/172.18.0.2:54310
2020-01-07 21:53:59,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x41ba10f22d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 113 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-07 21:53:59,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1867106961-172.18.0.2-1578405220772
2020-01-07 21:55:42,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1867106961-172.18.0.2-1578405220772:blk_1073741825_1001 src: /172.18.0.2:59738 dest: /172.18.0.4:50010
2020-01-07 21:55:42,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:59738, dest: /172.18.0.4:50010, bytes: 524288, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_69774887_1, offset: 0, srvID: c36601a6-67c6-4070-a520-005665f1895c, blockid: BP-1867106961-172.18.0.2-1578405220772:blk_1073741825_1001, duration: 135419746
2020-01-07 21:55:42,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1867106961-172.18.0.2-1578405220772:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-01-07 21:56:43,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1867106961-172.18.0.2-1578405220772:blk_1073741826_1002 src: /172.18.0.4:58182 dest: /172.18.0.4:50010
2020-01-07 21:56:43,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1867106961-172.18.0.2-1578405220772:blk_1073741827_1003 src: /172.18.0.3:35974 dest: /172.18.0.4:50010
2020-01-07 21:56:43,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:35974, dest: /172.18.0.4:50010, bytes: 819, op: HDFS_WRITE, cliID: DFSClient_attempt_20200107215632_0000_m_000000_0_719228819_26, offset: 0, srvID: c36601a6-67c6-4070-a520-005665f1895c, blockid: BP-1867106961-172.18.0.2-1578405220772:blk_1073741827_1003, duration: 175084923
2020-01-07 21:56:43,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1867106961-172.18.0.2-1578405220772:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-01-07 21:56:43,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:58182, dest: /172.18.0.4:50010, bytes: 959, op: HDFS_WRITE, cliID: DFSClient_attempt_20200107215632_0000_m_000001_0_-1081221383_26, offset: 0, srvID: c36601a6-67c6-4070-a520-005665f1895c, blockid: BP-1867106961-172.18.0.2-1578405220772:blk_1073741826_1002, duration: 226493632
2020-01-07 21:56:43,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1867106961-172.18.0.2-1578405220772:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-01-08 20:03:02,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-01-08 20:03:02,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-01-08 20:03:04,997 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-01-08 20:03:05,276 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-01-08 20:03:05,277 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-01-08 20:03:05,295 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-01-08 20:03:05,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2020-01-08 20:03:05,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-01-08 20:03:05,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-01-08 20:03:05,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-01-08 20:03:05,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-01-08 20:03:05,804 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-01-08 20:03:05,824 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-01-08 20:03:05,840 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-01-08 20:03:05,861 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-01-08 20:03:05,864 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-01-08 20:03:05,865 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-01-08 20:03:05,866 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-01-08 20:03:05,906 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41175
2020-01-08 20:03:05,907 INFO org.mortbay.log: jetty-6.1.26
2020-01-08 20:03:06,642 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41175
2020-01-08 20:03:07,054 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-01-08 20:03:07,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-01-08 20:03:07,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-01-08 20:03:07,357 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-01-08 20:03:07,415 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-01-08 20:03:07,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-01-08 20:03:07,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-01-08 20:03:07,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-01-08 20:03:07,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-01-08 20:03:07,661 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-01-08 20:03:07,663 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-01-08 20:03:09,332 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 66@slave2
2020-01-08 20:03:09,338 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-357219292-172.18.0.2-1578484967825
2020-01-08 20:03:09,339 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-01-08 20:03:09,498 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-357219292-172.18.0.2-1578484967825
2020-01-08 20:03:09,498 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-357219292-172.18.0.2-1578484967825
2020-01-08 20:03:09,501 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-357219292-172.18.0.2-1578484967825 is not formatted for BP-357219292-172.18.0.2-1578484967825
2020-01-08 20:03:09,502 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-01-08 20:03:09,502 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-357219292-172.18.0.2-1578484967825 directory /tmp/hadoop/dfs/data/current/BP-357219292-172.18.0.2-1578484967825/current
2020-01-08 20:03:09,506 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-01-08 20:03:09,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=556464122;bpid=BP-357219292-172.18.0.2-1578484967825;lv=-56;nsInfo=lv=-63;cid=CID-375de391-058f-41db-ab27-811d5cf20c52;nsid=556464122;c=0;bpid=BP-357219292-172.18.0.2-1578484967825;dnuuid=null
2020-01-08 20:03:09,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 143d107c-c60a-4324-8a3f-d67b41b0ee76
2020-01-08 20:03:09,668 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-7f574cf9-41ab-4e4e-ac99-6f082fc06367
2020-01-08 20:03:09,669 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-01-08 20:03:09,678 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-01-08 20:03:09,679 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-357219292-172.18.0.2-1578484967825
2020-01-08 20:03:09,682 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-357219292-172.18.0.2-1578484967825 on volume /tmp/hadoop/dfs/data/current...
2020-01-08 20:03:09,791 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-357219292-172.18.0.2-1578484967825 on /tmp/hadoop/dfs/data/current: 108ms
2020-01-08 20:03:09,792 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-357219292-172.18.0.2-1578484967825: 112ms
2020-01-08 20:03:09,794 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-357219292-172.18.0.2-1578484967825 on volume /tmp/hadoop/dfs/data/current...
2020-01-08 20:03:09,795 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-357219292-172.18.0.2-1578484967825 on volume /tmp/hadoop/dfs/data/current: 0ms
2020-01-08 20:03:09,795 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 3ms
2020-01-08 20:03:10,321 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-357219292-172.18.0.2-1578484967825 on volume /tmp/hadoop/dfs/data
2020-01-08 20:03:10,335 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7f574cf9-41ab-4e4e-ac99-6f082fc06367): finished scanning block pool BP-357219292-172.18.0.2-1578484967825
2020-01-08 20:03:10,345 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1578499054345 with interval 21600000
2020-01-08 20:03:10,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-357219292-172.18.0.2-1578484967825 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-01-08 20:03:10,505 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7f574cf9-41ab-4e4e-ac99-6f082fc06367): no suitable block pools found to scan.  Waiting 1814399816 ms.
2020-01-08 20:03:10,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-357219292-172.18.0.2-1578484967825 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-01-08 20:03:10,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-01-08 20:03:10,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-357219292-172.18.0.2-1578484967825 (Datanode Uuid 143d107c-c60a-4324-8a3f-d67b41b0ee76) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-01-08 20:03:10,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-357219292-172.18.0.2-1578484967825 (Datanode Uuid 143d107c-c60a-4324-8a3f-d67b41b0ee76) service to master/172.18.0.2:54310
2020-01-08 20:03:11,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x198a2dfe4d7d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 202 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-08 20:03:11,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-08 23:11:32,507 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 14397ms
No GCs detected
2020-01-09 03:07:18,282 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-09 04:08:59,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x299972abad4d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-09 04:08:59,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-09 16:06:24,806 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 14127ms
No GCs detected
2020-01-09 17:12:38,014 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-09 18:12:28,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x3d3e97196941,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-09 18:12:28,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-09 21:08:39,196 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10504ms
No GCs detected
2020-01-10 00:05:37,655 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12526ms
No GCs detected
2020-01-10 07:03:27,828 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1001ms
No GCs detected
2020-01-10 07:58:51,501 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 14763ms
No GCs detected
2020-01-10 15:39:22,496 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9695ms
No GCs detected
2020-01-10 20:49:00,472 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 18646ms
No GCs detected
2020-01-10 21:02:54,498 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-10 22:02:44,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x50e3bb8be27d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 16 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-10 22:02:44,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-11 18:42:36,051 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13357ms
No GCs detected
2020-01-11 22:18:17,552 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 15119ms
No GCs detected
2020-01-11 23:44:04,477 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-12 00:43:54,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x6488df995b15,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 20 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-12 00:43:54,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-12 05:43:39,086 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-12 06:43:29,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x782e03ec3885,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-12 06:43:29,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-12 21:18:58,275 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-12 22:18:48,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x8bd32841aa1d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-12 22:18:48,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-13 03:51:22,303 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13207ms
No GCs detected
2020-01-13 06:02:54,283 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13022ms
No GCs detected
2020-01-13 10:21:39,827 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11740ms
No GCs detected
2020-01-13 13:11:46,301 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6484ms
No GCs detected
2020-01-13 17:49:30,447 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-13 21:39:11,472 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12943ms
No GCs detected
2020-01-13 22:39:49,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x9f784c960275,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 22 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-13 22:39:49,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-14 06:19:55,572 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-14 07:19:45,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xb31d70e4b771,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-14 07:19:45,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-14 14:55:34,929 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 17434ms
No GCs detected
2020-01-14 15:55:35,045 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9414ms
No GCs detected
2020-01-14 18:28:43,027 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8891ms
No GCs detected
2020-01-15 01:52:05,582 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-15 03:14:36,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xc6c295298351,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 15 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-15 03:14:36,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-15 08:14:22,028 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-15 09:14:12,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xda67b9b7d2b9,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-15 09:14:12,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-15 16:09:41,022 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 37677ms
No GCs detected
2020-01-15 16:17:41,362 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-15 17:30:42,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xee0cddd49499,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-15 17:30:42,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-16 02:28:02,140 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-16 04:25:45,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x101b20241bed9,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-16 04:25:45,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-16 17:29:57,052 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-16 18:38:58,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1155726c331ad,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-16 18:38:58,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-16 20:37:09,538 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 15365ms
No GCs detected
2020-01-17 00:44:48,265 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12866ms
No GCs detected
2020-01-17 02:58:06,522 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1166ms
No GCs detected
2020-01-17 04:10:53,750 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-17 05:13:02,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x128fc4af06d21,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 11 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-17 05:13:02,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-17 19:02:14,200 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-17 19:08:37,113 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 14342ms
No GCs detected
2020-01-17 21:33:16,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x13ca16f2c7735,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-17 21:33:16,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-18 01:14:56,727 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10340ms
No GCs detected
2020-01-18 08:14:04,005 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-18 09:13:54,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x15046938bd2b1,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 13 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-18 09:13:54,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-18 10:48:30,805 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10048ms
No GCs detected
2020-01-18 17:01:17,041 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5584ms
No GCs detected
2020-01-19 00:43:27,732 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-19 01:43:17,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x163ebb7ef4445,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 17 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-19 01:43:17,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-19 02:37:20,535 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12003ms
No GCs detected
2020-01-19 06:16:56,688 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7593ms
No GCs detected
2020-01-19 22:58:35,125 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8926ms
No GCs detected
2020-01-20 03:20:51,646 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-20 04:20:41,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x17790dc1ee17d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 15 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-20 04:20:41,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-20 05:19:26,726 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1238ms
No GCs detected
2020-01-20 09:20:26,260 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-20 10:54:56,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x18b3600673225,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-20 10:54:56,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-20 16:53:07,736 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11344ms
No GCs detected
2020-01-20 20:55:53,037 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10974ms
No GCs detected
2020-01-20 23:49:31,703 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10424ms
No GCs detected
2020-01-21 04:27:08,089 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-21 05:26:58,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x19edb24ca3e29,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 24 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-21 05:26:58,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-21 10:26:42,687 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-21 11:26:32,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1b2804915d325,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 15 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-21 11:26:32,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-21 21:03:06,165 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13562ms
No GCs detected
2020-01-22 01:24:08,797 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-22 02:23:58,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1c6256d820559,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 23 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-22 02:23:58,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-22 04:05:34,752 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11837ms
No GCs detected
2020-01-22 16:16:19,144 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10431ms
No GCs detected
2020-01-22 16:47:50,167 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-22 17:47:40,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1d9ca9201f381,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 46 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-22 17:47:40,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-23 00:10:47,195 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10681ms
No GCs detected
2020-01-23 02:05:49,650 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-23 06:16:02,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1ed6fb6244279,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 42 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-23 06:16:02,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-23 19:10:50,471 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-23 20:10:41,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x20114daad3efd,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-23 20:10:41,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-23 23:38:29,785 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 18735ms
No GCs detected
2020-01-24 02:28:43,551 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10407ms
No GCs detected
2020-01-24 05:46:32,250 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-24 06:46:22,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x214b9feca5ca9,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 26 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-24 06:46:22,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-24 07:18:30,134 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13251ms
No GCs detected
2020-01-24 15:39:07,580 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8482ms
No GCs detected
2020-01-24 22:05:26,516 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-24 23:05:16,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2285f2332b8d5,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 29 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-24 23:05:16,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-24 23:58:48,799 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1800ms
No GCs detected
2020-01-25 02:23:37,892 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11806ms
No GCs detected
2020-01-25 08:11:03,381 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9510ms
No GCs detected
2020-01-25 09:04:33,024 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-25 17:16:33,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x23c0447d7ceb5,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 18 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-25 17:16:33,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-25 23:28:39,504 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11392ms
No GCs detected
2020-01-26 00:41:07,764 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7790ms
No GCs detected
2020-01-26 04:42:24,515 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6367ms
No GCs detected
2020-01-26 05:30:49,367 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-26 06:32:00,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x24fa96bc2d2fd,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-26 06:32:00,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-26 18:36:48,025 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10125ms
No GCs detected
2020-01-26 22:34:50,602 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-26 23:34:40,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2634e901acdcd,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 13 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-26 23:34:40,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-27 04:34:25,276 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-27 05:34:15,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x276f3b463cea1,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-27 05:34:15,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-27 08:04:15,596 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11127ms
No GCs detected
2020-01-27 09:07:38,667 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5830ms
No GCs detected
2020-01-27 09:07:55,202 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4928ms
No GCs detected
2020-01-27 20:27:57,939 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-27 22:11:40,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x28a98d8b31fdd,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 14 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-27 22:11:40,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-28 06:02:17,489 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-28 07:02:07,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x29e3dfd27da0d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-28 07:02:07,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-28 21:06:48,018 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-28 22:06:38,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2b1e32194f1f1,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-28 22:06:38,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-29 05:07:09,359 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-29 06:06:59,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2c58845bb4379,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-29 06:06:59,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-29 16:08:53,442 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 40356ms
No GCs detected
2020-02-04 23:29:48,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-02-04 23:29:49,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-04 23:29:50,539 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-04 23:29:50,636 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-04 23:29:50,637 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-02-04 23:29:50,649 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-02-04 23:29:50,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2020-02-04 23:29:50,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-02-04 23:29:50,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-02-04 23:29:50,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-02-04 23:29:50,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-02-04 23:29:50,945 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-04 23:29:50,957 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-02-04 23:29:50,975 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-02-04 23:29:50,992 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-04 23:29:50,996 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-02-04 23:29:50,997 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-04 23:29:50,997 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-04 23:29:51,020 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46285
2020-02-04 23:29:51,021 INFO org.mortbay.log: jetty-6.1.26
2020-02-04 23:29:51,713 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46285
2020-02-04 23:29:52,088 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-02-04 23:29:52,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-02-04 23:29:52,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-02-04 23:29:52,264 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-02-04 23:29:52,294 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-02-04 23:29:52,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-02-04 23:29:52,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-02-04 23:29:52,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-02-04 23:29:52,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-02-04 23:29:52,452 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-02-04 23:29:52,452 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-02-04 23:29:53,339 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 67@slave2
2020-02-04 23:29:53,344 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1169086459-172.18.0.2-1580830175855
2020-02-04 23:29:53,346 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-04 23:29:53,518 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1169086459-172.18.0.2-1580830175855
2020-02-04 23:29:53,519 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1169086459-172.18.0.2-1580830175855
2020-02-04 23:29:53,520 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1169086459-172.18.0.2-1580830175855 is not formatted for BP-1169086459-172.18.0.2-1580830175855
2020-02-04 23:29:53,520 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-04 23:29:53,521 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1169086459-172.18.0.2-1580830175855 directory /tmp/hadoop/dfs/data/current/BP-1169086459-172.18.0.2-1580830175855/current
2020-02-04 23:29:53,523 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-02-04 23:29:53,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=347583735;bpid=BP-1169086459-172.18.0.2-1580830175855;lv=-56;nsInfo=lv=-63;cid=CID-23d1b847-449c-4728-bbbd-c5eee3b535b7;nsid=347583735;c=0;bpid=BP-1169086459-172.18.0.2-1580830175855;dnuuid=null
2020-02-04 23:29:53,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 3538658e-9e69-4b70-b71c-dc71c4afda50
2020-02-04 23:29:53,605 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-9db96703-dd30-4f86-878e-54ab61202962
2020-02-04 23:29:53,606 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-02-04 23:29:53,611 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-02-04 23:29:53,612 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1169086459-172.18.0.2-1580830175855
2020-02-04 23:29:53,613 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1169086459-172.18.0.2-1580830175855 on volume /tmp/hadoop/dfs/data/current...
2020-02-04 23:29:53,717 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1169086459-172.18.0.2-1580830175855 on /tmp/hadoop/dfs/data/current: 103ms
2020-02-04 23:29:53,718 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1169086459-172.18.0.2-1580830175855: 106ms
2020-02-04 23:29:53,719 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1169086459-172.18.0.2-1580830175855 on volume /tmp/hadoop/dfs/data/current...
2020-02-04 23:29:53,720 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1169086459-172.18.0.2-1580830175855 on volume /tmp/hadoop/dfs/data/current: 0ms
2020-02-04 23:29:53,721 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 2ms
2020-02-04 23:29:53,977 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1169086459-172.18.0.2-1580830175855 on volume /tmp/hadoop/dfs/data
2020-02-04 23:29:53,985 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9db96703-dd30-4f86-878e-54ab61202962): finished scanning block pool BP-1169086459-172.18.0.2-1580830175855
2020-02-04 23:29:53,995 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1580838980995 with interval 21600000
2020-02-04 23:29:54,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1169086459-172.18.0.2-1580830175855 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-02-04 23:29:54,087 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9db96703-dd30-4f86-878e-54ab61202962): no suitable block pools found to scan.  Waiting 1814399885 ms.
2020-02-04 23:29:54,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1169086459-172.18.0.2-1580830175855 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-02-04 23:29:54,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-02-04 23:29:54,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1169086459-172.18.0.2-1580830175855 (Datanode Uuid 3538658e-9e69-4b70-b71c-dc71c4afda50) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-02-04 23:29:54,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1169086459-172.18.0.2-1580830175855 (Datanode Uuid 3538658e-9e69-4b70-b71c-dc71c4afda50) service to master/172.18.0.2:54310
2020-02-04 23:29:54,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x3ded6fd8f45,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 93 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-04 23:29:54,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1169086459-172.18.0.2-1580830175855
2020-02-04 23:36:33,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-02-04 23:36:33,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-04 23:36:35,599 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-04 23:36:35,791 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-04 23:36:35,792 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-02-04 23:36:35,810 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-02-04 23:36:35,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2020-02-04 23:36:35,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-02-04 23:36:35,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-02-04 23:36:35,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-02-04 23:36:35,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-02-04 23:36:36,270 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-04 23:36:36,283 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-02-04 23:36:36,301 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-02-04 23:36:36,331 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-04 23:36:36,336 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-02-04 23:36:36,337 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-04 23:36:36,338 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-04 23:36:36,390 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35871
2020-02-04 23:36:36,391 INFO org.mortbay.log: jetty-6.1.26
2020-02-04 23:36:37,302 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:35871
2020-02-04 23:36:37,723 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-02-04 23:36:37,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-02-04 23:36:37,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-02-04 23:36:37,986 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-02-04 23:36:38,041 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-02-04 23:36:38,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-02-04 23:36:38,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-02-04 23:36:38,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-02-04 23:36:38,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-02-04 23:36:38,254 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-02-04 23:36:38,269 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-02-04 23:36:39,405 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 68@slave2
2020-02-04 23:36:39,409 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1725807159-172.18.0.2-1580830580814
2020-02-04 23:36:39,409 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-04 23:36:39,518 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1725807159-172.18.0.2-1580830580814
2020-02-04 23:36:39,519 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1725807159-172.18.0.2-1580830580814
2020-02-04 23:36:39,522 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1725807159-172.18.0.2-1580830580814 is not formatted for BP-1725807159-172.18.0.2-1580830580814
2020-02-04 23:36:39,523 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-04 23:36:39,523 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1725807159-172.18.0.2-1580830580814 directory /tmp/hadoop/dfs/data/current/BP-1725807159-172.18.0.2-1580830580814/current
2020-02-04 23:36:39,526 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-02-04 23:36:39,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=439303543;bpid=BP-1725807159-172.18.0.2-1580830580814;lv=-56;nsInfo=lv=-63;cid=CID-00a4f34f-3c65-433e-9acd-430f9e878a24;nsid=439303543;c=0;bpid=BP-1725807159-172.18.0.2-1580830580814;dnuuid=null
2020-02-04 23:36:39,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 558ff85e-379f-49b9-b7a4-23fa9eff942d
2020-02-04 23:36:39,765 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-af0344da-a5a0-44e4-a6d3-3bee91803fde
2020-02-04 23:36:39,766 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-02-04 23:36:39,785 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-02-04 23:36:39,787 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1725807159-172.18.0.2-1580830580814
2020-02-04 23:36:39,791 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1725807159-172.18.0.2-1580830580814 on volume /tmp/hadoop/dfs/data/current...
2020-02-04 23:36:39,917 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1725807159-172.18.0.2-1580830580814 on /tmp/hadoop/dfs/data/current: 125ms
2020-02-04 23:36:39,918 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1725807159-172.18.0.2-1580830580814: 130ms
2020-02-04 23:36:39,920 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1725807159-172.18.0.2-1580830580814 on volume /tmp/hadoop/dfs/data/current...
2020-02-04 23:36:39,921 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1725807159-172.18.0.2-1580830580814 on volume /tmp/hadoop/dfs/data/current: 0ms
2020-02-04 23:36:39,922 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 3ms
2020-02-04 23:36:40,385 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1725807159-172.18.0.2-1580830580814 on volume /tmp/hadoop/dfs/data
2020-02-04 23:36:40,396 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-af0344da-a5a0-44e4-a6d3-3bee91803fde): finished scanning block pool BP-1725807159-172.18.0.2-1580830580814
2020-02-04 23:36:40,418 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1580844938418 with interval 21600000
2020-02-04 23:36:40,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1725807159-172.18.0.2-1580830580814 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-02-04 23:36:40,553 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-af0344da-a5a0-44e4-a6d3-3bee91803fde): no suitable block pools found to scan.  Waiting 1814399831 ms.
2020-02-04 23:36:40,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1725807159-172.18.0.2-1580830580814 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-02-04 23:36:40,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-02-04 23:36:40,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1725807159-172.18.0.2-1580830580814 (Datanode Uuid 558ff85e-379f-49b9-b7a4-23fa9eff942d) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-02-04 23:36:40,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1725807159-172.18.0.2-1580830580814 (Datanode Uuid 558ff85e-379f-49b9-b7a4-23fa9eff942d) service to master/172.18.0.2:54310
2020-02-04 23:36:41,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x43d91f70514,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 156 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-04 23:36:41,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1725807159-172.18.0.2-1580830580814
2020-02-04 23:38:21,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1725807159-172.18.0.2-1580830580814:blk_1073741825_1001 src: /172.18.0.2:52786 dest: /172.18.0.4:50010
2020-02-04 23:38:21,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:52786, dest: /172.18.0.4:50010, bytes: 524288, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_847818006_1, offset: 0, srvID: 558ff85e-379f-49b9-b7a4-23fa9eff942d, blockid: BP-1725807159-172.18.0.2-1580830580814:blk_1073741825_1001, duration: 160651604
2020-02-04 23:38:21,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1725807159-172.18.0.2-1580830580814:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-02-05 01:03:15,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-02-05 01:03:15,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-05 01:03:17,379 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-05 01:03:17,556 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-05 01:03:17,557 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-02-05 01:03:17,567 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-02-05 01:03:17,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2020-02-05 01:03:17,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-02-05 01:03:17,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-02-05 01:03:17,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-02-05 01:03:17,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-02-05 01:03:17,988 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-05 01:03:18,016 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-02-05 01:03:18,039 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-02-05 01:03:18,072 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-05 01:03:18,075 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-02-05 01:03:18,076 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-05 01:03:18,076 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-05 01:03:18,120 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46229
2020-02-05 01:03:18,121 INFO org.mortbay.log: jetty-6.1.26
2020-02-05 01:03:19,008 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46229
2020-02-05 01:03:19,521 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-02-05 01:03:19,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-02-05 01:03:19,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-02-05 01:03:19,748 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-02-05 01:03:19,791 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-02-05 01:03:19,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-02-05 01:03:19,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-02-05 01:03:19,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-02-05 01:03:20,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-02-05 01:03:20,035 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-02-05 01:03:20,044 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-02-05 01:03:21,246 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 69@slave2
2020-02-05 01:03:21,250 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-777553246-172.18.0.2-1580835783055
2020-02-05 01:03:21,251 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-05 01:03:21,379 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-777553246-172.18.0.2-1580835783055
2020-02-05 01:03:21,380 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-777553246-172.18.0.2-1580835783055
2020-02-05 01:03:21,384 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-777553246-172.18.0.2-1580835783055 is not formatted for BP-777553246-172.18.0.2-1580835783055
2020-02-05 01:03:21,384 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-05 01:03:21,385 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-777553246-172.18.0.2-1580835783055 directory /tmp/hadoop/dfs/data/current/BP-777553246-172.18.0.2-1580835783055/current
2020-02-05 01:03:21,388 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-02-05 01:03:21,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=735948749;bpid=BP-777553246-172.18.0.2-1580835783055;lv=-56;nsInfo=lv=-63;cid=CID-464cb930-5507-4ee4-ae8d-9a0d636c3a06;nsid=735948749;c=0;bpid=BP-777553246-172.18.0.2-1580835783055;dnuuid=null
2020-02-05 01:03:21,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 9e0cf61a-b677-4083-8488-e43b979aed80
2020-02-05 01:03:21,549 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-53e61f55-073e-4529-b6a3-63495cf3ac95
2020-02-05 01:03:21,550 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-02-05 01:03:21,556 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-02-05 01:03:21,557 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-777553246-172.18.0.2-1580835783055
2020-02-05 01:03:21,559 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-777553246-172.18.0.2-1580835783055 on volume /tmp/hadoop/dfs/data/current...
2020-02-05 01:03:21,676 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-777553246-172.18.0.2-1580835783055 on /tmp/hadoop/dfs/data/current: 116ms
2020-02-05 01:03:21,677 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-777553246-172.18.0.2-1580835783055: 119ms
2020-02-05 01:03:21,678 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-777553246-172.18.0.2-1580835783055 on volume /tmp/hadoop/dfs/data/current...
2020-02-05 01:03:21,680 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-777553246-172.18.0.2-1580835783055 on volume /tmp/hadoop/dfs/data/current: 1ms
2020-02-05 01:03:21,681 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 3ms
2020-02-05 01:03:22,002 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-777553246-172.18.0.2-1580835783055 on volume /tmp/hadoop/dfs/data
2020-02-05 01:03:22,009 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-53e61f55-073e-4529-b6a3-63495cf3ac95): finished scanning block pool BP-777553246-172.18.0.2-1580835783055
2020-02-05 01:03:22,022 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1580837141022 with interval 21600000
2020-02-05 01:03:22,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-777553246-172.18.0.2-1580835783055 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-02-05 01:03:22,143 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-53e61f55-073e-4529-b6a3-63495cf3ac95): no suitable block pools found to scan.  Waiting 1814399854 ms.
2020-02-05 01:03:22,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-777553246-172.18.0.2-1580835783055 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-02-05 01:03:22,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-02-05 01:03:22,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-777553246-172.18.0.2-1580835783055 (Datanode Uuid 9e0cf61a-b677-4083-8488-e43b979aed80) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-02-05 01:03:22,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-777553246-172.18.0.2-1580835783055 (Datanode Uuid 9e0cf61a-b677-4083-8488-e43b979aed80) service to master/172.18.0.2:54310
2020-02-05 01:03:22,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x8f98cdaf853,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 126 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-05 01:03:22,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-777553246-172.18.0.2-1580835783055
2020-02-05 01:16:13,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-02-05 01:16:13,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-05 01:16:15,436 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-05 01:16:15,663 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-05 01:16:15,664 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-02-05 01:16:15,677 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-02-05 01:16:15,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2020-02-05 01:16:15,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-02-05 01:16:15,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-02-05 01:16:15,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-02-05 01:16:15,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-02-05 01:16:16,153 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-05 01:16:16,180 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-02-05 01:16:16,202 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-02-05 01:16:16,222 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-05 01:16:16,227 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-02-05 01:16:16,228 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-05 01:16:16,230 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-05 01:16:16,282 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 43779
2020-02-05 01:16:16,283 INFO org.mortbay.log: jetty-6.1.26
2020-02-05 01:16:17,020 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:43779
2020-02-05 01:16:17,421 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-02-05 01:16:17,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-02-05 01:16:17,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-02-05 01:16:17,690 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-02-05 01:16:17,743 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-02-05 01:16:17,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-02-05 01:16:17,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-02-05 01:16:17,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-02-05 01:16:17,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-02-05 01:16:17,969 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-02-05 01:16:17,979 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-02-05 01:16:19,127 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 70@slave2
2020-02-05 01:16:19,130 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1474470855-172.18.0.2-1580836560765
2020-02-05 01:16:19,131 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-05 01:16:19,257 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1474470855-172.18.0.2-1580836560765
2020-02-05 01:16:19,258 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1474470855-172.18.0.2-1580836560765
2020-02-05 01:16:19,260 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1474470855-172.18.0.2-1580836560765 is not formatted for BP-1474470855-172.18.0.2-1580836560765
2020-02-05 01:16:19,260 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-05 01:16:19,261 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1474470855-172.18.0.2-1580836560765 directory /tmp/hadoop/dfs/data/current/BP-1474470855-172.18.0.2-1580836560765/current
2020-02-05 01:16:19,264 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-02-05 01:16:19,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=416019751;bpid=BP-1474470855-172.18.0.2-1580836560765;lv=-56;nsInfo=lv=-63;cid=CID-17a7ef30-ba6d-4ec4-8ab1-e50deff6ae90;nsid=416019751;c=0;bpid=BP-1474470855-172.18.0.2-1580836560765;dnuuid=null
2020-02-05 01:16:19,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 4831ccb4-41db-4933-bd35-fc0625b091e7
2020-02-05 01:16:19,544 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-9c7fb69b-05f8-4417-817b-37540ba72732
2020-02-05 01:16:19,546 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-02-05 01:16:19,564 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-02-05 01:16:19,565 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1474470855-172.18.0.2-1580836560765
2020-02-05 01:16:19,575 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1474470855-172.18.0.2-1580836560765 on volume /tmp/hadoop/dfs/data/current...
2020-02-05 01:16:19,704 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1474470855-172.18.0.2-1580836560765 on /tmp/hadoop/dfs/data/current: 128ms
2020-02-05 01:16:19,705 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1474470855-172.18.0.2-1580836560765: 139ms
2020-02-05 01:16:19,707 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1474470855-172.18.0.2-1580836560765 on volume /tmp/hadoop/dfs/data/current...
2020-02-05 01:16:19,708 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1474470855-172.18.0.2-1580836560765 on volume /tmp/hadoop/dfs/data/current: 0ms
2020-02-05 01:16:19,709 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 3ms
2020-02-05 01:16:20,067 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1474470855-172.18.0.2-1580836560765 on volume /tmp/hadoop/dfs/data
2020-02-05 01:16:20,080 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9c7fb69b-05f8-4417-817b-37540ba72732): finished scanning block pool BP-1474470855-172.18.0.2-1580836560765
2020-02-05 01:16:20,104 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1580847918104 with interval 21600000
2020-02-05 01:16:20,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1474470855-172.18.0.2-1580836560765 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-02-05 01:16:20,268 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9c7fb69b-05f8-4417-817b-37540ba72732): no suitable block pools found to scan.  Waiting 1814399799 ms.
2020-02-05 01:16:20,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1474470855-172.18.0.2-1580836560765 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-02-05 01:16:20,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-02-05 01:16:20,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1474470855-172.18.0.2-1580836560765 (Datanode Uuid 4831ccb4-41db-4933-bd35-fc0625b091e7) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-02-05 01:16:20,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1474470855-172.18.0.2-1580836560765 (Datanode Uuid 4831ccb4-41db-4933-bd35-fc0625b091e7) service to master/172.18.0.2:54310
2020-02-05 01:16:20,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x9aed96e40fa,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 150 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-05 01:16:20,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1474470855-172.18.0.2-1580836560765
2020-02-05 01:20:20,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-02-05 01:20:20,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-05 01:20:22,497 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-05 01:20:22,665 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-05 01:20:22,666 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-02-05 01:20:22,676 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-02-05 01:20:22,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2020-02-05 01:20:22,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-02-05 01:20:22,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-02-05 01:20:22,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-02-05 01:20:22,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-02-05 01:20:23,099 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-05 01:20:23,133 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-02-05 01:20:23,156 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-02-05 01:20:23,181 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-05 01:20:23,187 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-02-05 01:20:23,188 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-05 01:20:23,190 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-05 01:20:23,246 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 39577
2020-02-05 01:20:23,248 INFO org.mortbay.log: jetty-6.1.26
2020-02-05 01:20:24,164 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:39577
2020-02-05 01:20:24,554 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-02-05 01:20:24,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-02-05 01:20:24,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-02-05 01:20:24,837 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-02-05 01:20:24,889 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-02-05 01:20:24,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-02-05 01:20:25,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-02-05 01:20:25,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-02-05 01:20:25,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-02-05 01:20:25,100 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-02-05 01:20:25,110 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-02-05 01:20:26,148 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 70@slave2
2020-02-05 01:20:26,152 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-518620581-172.18.0.2-1580836808020
2020-02-05 01:20:26,153 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-05 01:20:26,303 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-518620581-172.18.0.2-1580836808020
2020-02-05 01:20:26,304 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-518620581-172.18.0.2-1580836808020
2020-02-05 01:20:26,307 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-518620581-172.18.0.2-1580836808020 is not formatted for BP-518620581-172.18.0.2-1580836808020
2020-02-05 01:20:26,307 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-05 01:20:26,308 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-518620581-172.18.0.2-1580836808020 directory /tmp/hadoop/dfs/data/current/BP-518620581-172.18.0.2-1580836808020/current
2020-02-05 01:20:26,311 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-02-05 01:20:26,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1975424816;bpid=BP-518620581-172.18.0.2-1580836808020;lv=-56;nsInfo=lv=-63;cid=CID-5f3fd106-baa9-4b10-9d23-5d0896103f89;nsid=1975424816;c=0;bpid=BP-518620581-172.18.0.2-1580836808020;dnuuid=null
2020-02-05 01:20:26,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID e15e50ca-7079-4aa3-b2c4-779e0c79cb9c
2020-02-05 01:20:26,424 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-5f0bc728-f21e-4e31-b187-f828aa339de8
2020-02-05 01:20:26,425 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-02-05 01:20:26,440 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-02-05 01:20:26,441 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-518620581-172.18.0.2-1580836808020
2020-02-05 01:20:26,449 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-518620581-172.18.0.2-1580836808020 on volume /tmp/hadoop/dfs/data/current...
2020-02-05 01:20:26,555 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-518620581-172.18.0.2-1580836808020 on /tmp/hadoop/dfs/data/current: 105ms
2020-02-05 01:20:26,556 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-518620581-172.18.0.2-1580836808020: 114ms
2020-02-05 01:20:26,557 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-518620581-172.18.0.2-1580836808020 on volume /tmp/hadoop/dfs/data/current...
2020-02-05 01:20:26,558 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-518620581-172.18.0.2-1580836808020 on volume /tmp/hadoop/dfs/data/current: 1ms
2020-02-05 01:20:26,559 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 2ms
2020-02-05 01:20:26,950 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-518620581-172.18.0.2-1580836808020 on volume /tmp/hadoop/dfs/data
2020-02-05 01:20:26,959 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5f0bc728-f21e-4e31-b187-f828aa339de8): finished scanning block pool BP-518620581-172.18.0.2-1580836808020
2020-02-05 01:20:26,982 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1580854226982 with interval 21600000
2020-02-05 01:20:27,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-518620581-172.18.0.2-1580836808020 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-02-05 01:20:27,105 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5f0bc728-f21e-4e31-b187-f828aa339de8): no suitable block pools found to scan.  Waiting 1814399843 ms.
2020-02-05 01:20:27,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-518620581-172.18.0.2-1580836808020 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-02-05 01:20:27,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-02-05 01:20:27,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-518620581-172.18.0.2-1580836808020 (Datanode Uuid e15e50ca-7079-4aa3-b2c4-779e0c79cb9c) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-02-05 01:20:27,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-518620581-172.18.0.2-1580836808020 (Datanode Uuid e15e50ca-7079-4aa3-b2c4-779e0c79cb9c) service to master/172.18.0.2:54310
2020-02-05 01:20:27,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x9e85d2c72fe,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 122 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-05 01:20:27,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-518620581-172.18.0.2-1580836808020
2020-02-05 04:03:18,534 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 21979ms
No GCs detected
2020-02-05 06:42:15,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x14822ac450dc,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 11 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-05 06:42:16,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-518620581-172.18.0.2-1580836808020
2020-02-05 08:17:53,353 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-518620581-172.18.0.2-1580836808020 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-02-05 10:58:07,895 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 17350ms
No GCs detected
2020-02-05 10:58:44,235 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10448ms
No GCs detected
2020-02-05 20:02:49,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x28274f0697d0,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-05 20:02:49,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-518620581-172.18.0.2-1580836808020
2020-02-06 02:27:16,335 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-518620581-172.18.0.2-1580836808020 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-02-06 17:52:40,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-02-06 17:52:40,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-06 17:52:42,028 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-06 17:52:42,199 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-06 17:52:42,200 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-02-06 17:52:42,213 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-02-06 17:52:42,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2020-02-06 17:52:42,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-02-06 17:52:42,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-02-06 17:52:42,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-02-06 17:52:42,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-02-06 17:52:42,665 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-06 17:52:42,693 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-02-06 17:52:42,717 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-02-06 17:52:42,740 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-06 17:52:42,744 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-02-06 17:52:42,745 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-06 17:52:42,747 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-06 17:52:42,792 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40599
2020-02-06 17:52:42,793 INFO org.mortbay.log: jetty-6.1.26
2020-02-06 17:52:43,619 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40599
2020-02-06 17:52:44,105 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-02-06 17:52:44,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-02-06 17:52:44,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-02-06 17:52:44,444 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-02-06 17:52:44,499 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-02-06 17:52:44,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-02-06 17:52:44,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-02-06 17:52:44,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-02-06 17:52:44,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-02-06 17:52:44,732 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-02-06 17:52:44,743 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-02-06 17:52:46,834 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 70@slave2
2020-02-06 17:52:46,841 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1913368944-172.18.0.2-1580982745626
2020-02-06 17:52:46,842 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-06 17:52:47,240 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1913368944-172.18.0.2-1580982745626
2020-02-06 17:52:47,241 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1913368944-172.18.0.2-1580982745626
2020-02-06 17:52:47,247 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1913368944-172.18.0.2-1580982745626 is not formatted for BP-1913368944-172.18.0.2-1580982745626
2020-02-06 17:52:47,248 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-06 17:52:47,248 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1913368944-172.18.0.2-1580982745626 directory /tmp/hadoop/dfs/data/current/BP-1913368944-172.18.0.2-1580982745626/current
2020-02-06 17:52:47,252 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-02-06 17:52:47,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1505753509;bpid=BP-1913368944-172.18.0.2-1580982745626;lv=-56;nsInfo=lv=-63;cid=CID-71db67d9-2ed5-4c6c-b2ce-c2ff4951615a;nsid=1505753509;c=0;bpid=BP-1913368944-172.18.0.2-1580982745626;dnuuid=null
2020-02-06 17:52:47,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 442057d4-78ad-4147-9ec5-85da5fb761a6
2020-02-06 17:52:47,417 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-189cd511-32c1-4e9a-a9e9-f808316bc179
2020-02-06 17:52:47,418 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-02-06 17:52:47,442 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-02-06 17:52:47,444 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1913368944-172.18.0.2-1580982745626
2020-02-06 17:52:47,453 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1913368944-172.18.0.2-1580982745626 on volume /tmp/hadoop/dfs/data/current...
2020-02-06 17:52:47,627 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1913368944-172.18.0.2-1580982745626 on /tmp/hadoop/dfs/data/current: 172ms
2020-02-06 17:52:47,629 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1913368944-172.18.0.2-1580982745626: 184ms
2020-02-06 17:52:47,631 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1913368944-172.18.0.2-1580982745626 on volume /tmp/hadoop/dfs/data/current...
2020-02-06 17:52:47,632 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1913368944-172.18.0.2-1580982745626 on volume /tmp/hadoop/dfs/data/current: 1ms
2020-02-06 17:52:47,633 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 4ms
2020-02-06 17:52:48,299 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1913368944-172.18.0.2-1580982745626 on volume /tmp/hadoop/dfs/data
2020-02-06 17:52:48,311 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-189cd511-32c1-4e9a-a9e9-f808316bc179): finished scanning block pool BP-1913368944-172.18.0.2-1580982745626
2020-02-06 17:52:48,334 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1580986420333 with interval 21600000
2020-02-06 17:52:48,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1913368944-172.18.0.2-1580982745626 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-02-06 17:52:48,549 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-189cd511-32c1-4e9a-a9e9-f808316bc179): no suitable block pools found to scan.  Waiting 1814399749 ms.
2020-02-06 17:52:48,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1913368944-172.18.0.2-1580982745626 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-02-06 17:52:48,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-02-06 17:52:49,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1913368944-172.18.0.2-1580982745626 (Datanode Uuid 442057d4-78ad-4147-9ec5-85da5fb761a6) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-02-06 17:52:49,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1913368944-172.18.0.2-1580982745626 (Datanode Uuid 442057d4-78ad-4147-9ec5-85da5fb761a6) service to master/172.18.0.2:54310
2020-02-06 17:52:49,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x19a3d53d640,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 23 msec to generate and 469 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-06 17:52:49,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1913368944-172.18.0.2-1580982745626
2020-02-06 18:53:37,657 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1913368944-172.18.0.2-1580982745626 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-02-06 20:39:24,089 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11656ms
No GCs detected
2020-02-06 23:08:45,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xd3977786f7d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 27 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-06 23:08:45,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1913368944-172.18.0.2-1580982745626
