2020-01-07 21:53:53,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-01-07 21:53:53,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-01-07 21:53:54,550 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-01-07 21:53:54,705 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-01-07 21:53:54,706 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-01-07 21:53:54,715 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-01-07 21:53:54,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2020-01-07 21:53:54,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-01-07 21:53:54,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-01-07 21:53:54,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-01-07 21:53:54,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-01-07 21:53:55,078 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-01-07 21:53:55,101 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-01-07 21:53:55,125 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-01-07 21:53:55,144 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-01-07 21:53:55,147 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-01-07 21:53:55,148 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-01-07 21:53:55,149 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-01-07 21:53:55,177 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35353
2020-01-07 21:53:55,179 INFO org.mortbay.log: jetty-6.1.26
2020-01-07 21:53:55,951 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:35353
2020-01-07 21:53:56,334 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-01-07 21:53:56,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-01-07 21:53:56,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-01-07 21:53:56,562 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-01-07 21:53:56,598 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-01-07 21:53:56,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-01-07 21:53:56,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-01-07 21:53:56,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-01-07 21:53:56,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-01-07 21:53:56,819 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-01-07 21:53:56,821 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-01-07 21:53:57,884 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 66@slave1
2020-01-07 21:53:57,891 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1867106961-172.18.0.2-1578405220772
2020-01-07 21:53:57,892 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-01-07 21:53:57,997 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1867106961-172.18.0.2-1578405220772
2020-01-07 21:53:57,998 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1867106961-172.18.0.2-1578405220772
2020-01-07 21:53:58,002 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1867106961-172.18.0.2-1578405220772 is not formatted for BP-1867106961-172.18.0.2-1578405220772
2020-01-07 21:53:58,003 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-01-07 21:53:58,004 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1867106961-172.18.0.2-1578405220772 directory /tmp/hadoop/dfs/data/current/BP-1867106961-172.18.0.2-1578405220772/current
2020-01-07 21:53:58,007 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-01-07 21:53:58,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1500497699;bpid=BP-1867106961-172.18.0.2-1578405220772;lv=-56;nsInfo=lv=-63;cid=CID-652c6a67-0593-45df-a887-b603dda67864;nsid=1500497699;c=0;bpid=BP-1867106961-172.18.0.2-1578405220772;dnuuid=null
2020-01-07 21:53:58,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID d20fd2bf-cbde-42c1-be28-7411ed414de0
2020-01-07 21:53:58,168 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-0c3eaefc-d54f-4b43-8644-0262f0067426
2020-01-07 21:53:58,169 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-01-07 21:53:58,184 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-01-07 21:53:58,186 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1867106961-172.18.0.2-1578405220772
2020-01-07 21:53:58,189 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1867106961-172.18.0.2-1578405220772 on volume /tmp/hadoop/dfs/data/current...
2020-01-07 21:53:58,303 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1867106961-172.18.0.2-1578405220772 on /tmp/hadoop/dfs/data/current: 114ms
2020-01-07 21:53:58,303 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1867106961-172.18.0.2-1578405220772: 118ms
2020-01-07 21:53:58,305 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1867106961-172.18.0.2-1578405220772 on volume /tmp/hadoop/dfs/data/current...
2020-01-07 21:53:58,306 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1867106961-172.18.0.2-1578405220772 on volume /tmp/hadoop/dfs/data/current: 0ms
2020-01-07 21:53:58,306 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 2ms
2020-01-07 21:53:58,542 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1867106961-172.18.0.2-1578405220772 on volume /tmp/hadoop/dfs/data
2020-01-07 21:53:58,548 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0c3eaefc-d54f-4b43-8644-0262f0067426): finished scanning block pool BP-1867106961-172.18.0.2-1578405220772
2020-01-07 21:53:58,562 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1578413990562 with interval 21600000
2020-01-07 21:53:58,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1867106961-172.18.0.2-1578405220772 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-01-07 21:53:58,654 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0c3eaefc-d54f-4b43-8644-0262f0067426): no suitable block pools found to scan.  Waiting 1814399888 ms.
2020-01-07 21:53:58,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1867106961-172.18.0.2-1578405220772 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-01-07 21:53:58,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-01-07 21:53:58,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1867106961-172.18.0.2-1578405220772 (Datanode Uuid d20fd2bf-cbde-42c1-be28-7411ed414de0) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-01-07 21:53:58,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1867106961-172.18.0.2-1578405220772 (Datanode Uuid d20fd2bf-cbde-42c1-be28-7411ed414de0) service to master/172.18.0.2:54310
2020-01-07 21:53:59,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x41ba10fa14,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 113 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-07 21:53:59,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1867106961-172.18.0.2-1578405220772
2020-01-07 21:56:43,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1867106961-172.18.0.2-1578405220772:blk_1073741827_1003 src: /172.18.0.3:53108 dest: /172.18.0.3:50010
2020-01-07 21:56:43,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1867106961-172.18.0.2-1578405220772:blk_1073741826_1002 src: /172.18.0.4:35426 dest: /172.18.0.3:50010
2020-01-07 21:56:43,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:53108, dest: /172.18.0.3:50010, bytes: 819, op: HDFS_WRITE, cliID: DFSClient_attempt_20200107215632_0000_m_000000_0_719228819_26, offset: 0, srvID: d20fd2bf-cbde-42c1-be28-7411ed414de0, blockid: BP-1867106961-172.18.0.2-1578405220772:blk_1073741827_1003, duration: 193511744
2020-01-07 21:56:43,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1867106961-172.18.0.2-1578405220772:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-01-07 21:56:43,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:35426, dest: /172.18.0.3:50010, bytes: 959, op: HDFS_WRITE, cliID: DFSClient_attempt_20200107215632_0000_m_000001_0_-1081221383_26, offset: 0, srvID: d20fd2bf-cbde-42c1-be28-7411ed414de0, blockid: BP-1867106961-172.18.0.2-1578405220772:blk_1073741826_1002, duration: 191500749
2020-01-07 21:56:43,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1867106961-172.18.0.2-1578405220772:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-01-07 23:17:59,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x426ae3557ad,  containing 1 storage report(s), of which we sent 1. The reports had 2 total blocks and used 1 RPC(s). This took 11 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-07 23:17:59,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1867106961-172.18.0.2-1578405220772
2020-01-08 20:03:02,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-01-08 20:03:02,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-01-08 20:03:04,996 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-01-08 20:03:05,255 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-01-08 20:03:05,256 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-01-08 20:03:05,273 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-01-08 20:03:05,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2020-01-08 20:03:05,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-01-08 20:03:05,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-01-08 20:03:05,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-01-08 20:03:05,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-01-08 20:03:05,804 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-01-08 20:03:05,824 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-01-08 20:03:05,840 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-01-08 20:03:05,861 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-01-08 20:03:05,864 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-01-08 20:03:05,865 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-01-08 20:03:05,866 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-01-08 20:03:05,906 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34141
2020-01-08 20:03:05,907 INFO org.mortbay.log: jetty-6.1.26
2020-01-08 20:03:06,617 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:34141
2020-01-08 20:03:07,054 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-01-08 20:03:07,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-01-08 20:03:07,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-01-08 20:03:07,357 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-01-08 20:03:07,416 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-01-08 20:03:07,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-01-08 20:03:07,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-01-08 20:03:07,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-01-08 20:03:07,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-01-08 20:03:07,660 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-01-08 20:03:07,662 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-01-08 20:03:09,332 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 67@slave1
2020-01-08 20:03:09,338 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-357219292-172.18.0.2-1578484967825
2020-01-08 20:03:09,339 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-01-08 20:03:09,506 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-357219292-172.18.0.2-1578484967825
2020-01-08 20:03:09,506 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-357219292-172.18.0.2-1578484967825
2020-01-08 20:03:09,565 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-357219292-172.18.0.2-1578484967825 is not formatted for BP-357219292-172.18.0.2-1578484967825
2020-01-08 20:03:09,566 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-01-08 20:03:09,566 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-357219292-172.18.0.2-1578484967825 directory /tmp/hadoop/dfs/data/current/BP-357219292-172.18.0.2-1578484967825/current
2020-01-08 20:03:09,569 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-01-08 20:03:09,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=556464122;bpid=BP-357219292-172.18.0.2-1578484967825;lv=-56;nsInfo=lv=-63;cid=CID-375de391-058f-41db-ab27-811d5cf20c52;nsid=556464122;c=0;bpid=BP-357219292-172.18.0.2-1578484967825;dnuuid=null
2020-01-08 20:03:09,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID d82b4b71-8c89-4092-90fb-57f85c26b008
2020-01-08 20:03:09,708 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-10573894-d84f-4a71-9158-46e6650ee778
2020-01-08 20:03:09,709 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-01-08 20:03:09,723 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-01-08 20:03:09,724 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-357219292-172.18.0.2-1578484967825
2020-01-08 20:03:09,727 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-357219292-172.18.0.2-1578484967825 on volume /tmp/hadoop/dfs/data/current...
2020-01-08 20:03:09,839 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-357219292-172.18.0.2-1578484967825 on /tmp/hadoop/dfs/data/current: 112ms
2020-01-08 20:03:09,840 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-357219292-172.18.0.2-1578484967825: 115ms
2020-01-08 20:03:09,841 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-357219292-172.18.0.2-1578484967825 on volume /tmp/hadoop/dfs/data/current...
2020-01-08 20:03:09,842 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-357219292-172.18.0.2-1578484967825 on volume /tmp/hadoop/dfs/data/current: 1ms
2020-01-08 20:03:09,843 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 3ms
2020-01-08 20:03:10,303 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-357219292-172.18.0.2-1578484967825 on volume /tmp/hadoop/dfs/data
2020-01-08 20:03:10,321 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1578492326321 with interval 21600000
2020-01-08 20:03:10,322 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-10573894-d84f-4a71-9158-46e6650ee778): finished scanning block pool BP-357219292-172.18.0.2-1578484967825
2020-01-08 20:03:10,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-357219292-172.18.0.2-1578484967825 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-01-08 20:03:10,499 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-10573894-d84f-4a71-9158-46e6650ee778): no suitable block pools found to scan.  Waiting 1814399803 ms.
2020-01-08 20:03:10,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-357219292-172.18.0.2-1578484967825 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-01-08 20:03:10,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-01-08 20:03:10,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-357219292-172.18.0.2-1578484967825 (Datanode Uuid d82b4b71-8c89-4092-90fb-57f85c26b008) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-01-08 20:03:10,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-357219292-172.18.0.2-1578484967825 (Datanode Uuid d82b4b71-8c89-4092-90fb-57f85c26b008) service to master/172.18.0.2:54310
2020-01-08 20:03:11,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x198a2decdb15,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 203 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-08 20:03:11,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-08 23:11:32,523 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 14234ms
No GCs detected
2020-01-09 00:03:14,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cfaec213365,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 24 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-09 00:03:14,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-09 01:02:22,994 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-09 06:17:35,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x30a01066a6d9,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-09 06:17:35,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-09 07:16:43,705 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-09 16:06:24,662 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13554ms
No GCs detected
2020-01-09 21:08:39,350 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9911ms
No GCs detected
2020-01-09 23:37:52,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x444534ed5fad,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-09 23:37:52,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-10 00:05:37,868 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12555ms
No GCs detected
2020-01-10 06:26:19,875 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-10 07:58:52,384 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 14476ms
No GCs detected
2020-01-10 15:39:22,644 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9286ms
No GCs detected
2020-01-10 20:49:00,428 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 18821ms
No GCs detected
2020-01-11 18:42:36,190 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13369ms
No GCs detected
2020-01-11 19:35:21,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x57ea5a021811,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 15 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-11 19:35:21,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-11 20:34:30,007 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-11 22:18:17,563 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 15072ms
No GCs detected
2020-01-12 02:52:30,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x6b8f7d70a4ad,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-12 02:52:30,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-12 03:51:38,996 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-12 12:02:55,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x7f34a1cc3b51,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-12 12:02:55,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-12 19:07:05,389 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-13 01:48:58,173 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13545ms
No GCs detected
2020-01-13 05:34:23,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x92d9c62fde81,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-13 05:34:23,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-13 10:21:08,698 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13252ms
No GCs detected
2020-01-13 10:21:40,447 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11915ms
No GCs detected
2020-01-13 13:11:46,117 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6264ms
No GCs detected
2020-01-13 15:39:53,839 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-13 19:19:51,386 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12500ms
No GCs detected
2020-01-14 03:05:34,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xa67eea850e79,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-14 03:05:34,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-14 04:04:43,402 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-14 14:55:34,998 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 15899ms
No GCs detected
2020-01-14 15:55:35,209 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9502ms
No GCs detected
2020-01-14 18:28:42,957 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8884ms
No GCs detected
2020-01-14 22:04:12,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xba240f4f136d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-14 22:04:12,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-14 23:03:20,950 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-15 04:35:40,273 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1002ms
No GCs detected
2020-01-15 05:23:12,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xcdc9332d3419,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 20 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-15 05:23:12,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-15 06:22:21,896 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-15 11:22:48,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xe16e5769815d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-15 11:22:48,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-15 12:21:56,524 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-15 16:09:41,197 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 38002ms
No GCs detected
2020-01-15 23:36:53,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xf5137bce9ead,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-15 23:36:53,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-16 00:36:02,015 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-16 06:34:21,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x108b8a03d3fed,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-16 06:34:21,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-16 07:33:29,653 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-16 20:37:09,720 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 15516ms
No GCs detected
2020-01-16 23:17:11,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x11c5dc488025d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 25 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-16 23:17:11,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-17 00:28:50,868 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-17 00:44:48,261 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12502ms
No GCs detected
2020-01-17 02:58:06,524 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1103ms
No GCs detected
2020-01-17 07:21:39,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x13002e8f21b11,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 17 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-17 07:21:39,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-17 17:08:33,277 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-17 19:08:36,949 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 14577ms
No GCs detected
2020-01-18 04:31:38,646 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10540ms
No GCs detected
2020-01-18 04:53:02,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x143a80d4c2601,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-18 04:53:02,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-18 05:52:10,531 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-18 10:48:31,083 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10739ms
No GCs detected
2020-01-18 17:01:17,032 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5576ms
No GCs detected
2020-01-18 21:40:44,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1574d31655da1,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 180 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-18 21:40:44,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-18 22:39:52,638 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-19 02:37:20,660 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12079ms
No GCs detected
2020-01-19 06:16:56,907 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7829ms
No GCs detected
2020-01-19 22:58:35,011 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8859ms
No GCs detected
2020-01-20 00:05:25,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x16af25667b041,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 46 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-20 00:05:25,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-20 01:28:50,956 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-20 06:29:17,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x17e977a0c1dd5,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-20 06:29:17,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-20 07:28:26,137 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-20 16:53:07,337 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10838ms
No GCs detected
2020-01-20 18:24:54,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1923c9e6a40d1,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 39 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-20 18:24:54,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-20 19:35:53,173 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10458ms
No GCs detected
2020-01-20 21:31:00,002 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-20 23:49:31,940 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10286ms
No GCs detected
2020-01-21 07:35:34,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1a5e1c2bec6dd,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 15 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-21 07:35:34,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-21 08:34:42,564 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-21 21:03:06,470 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13477ms
No GCs detected
2020-01-21 22:33:00,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1b986e7b13bc5,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-21 22:33:00,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-21 23:32:08,709 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-22 02:49:47,868 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12303ms
No GCs detected
2020-01-22 05:48:33,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cd2c0bd7d20d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 21 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-22 05:48:33,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-22 06:47:42,011 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-22 13:20:04,579 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10403ms
No GCs detected
2020-01-22 21:34:05,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1e0d12fb392e9,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 16 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-22 21:34:05,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-23 00:10:47,021 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10994ms
No GCs detected
2020-01-23 00:13:49,532 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-23 08:24:38,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1f476541c2561,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 14 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-23 08:24:38,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-23 16:34:43,604 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-23 23:38:29,805 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 18659ms
No GCs detected
2020-01-24 02:43:07,396 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9897ms
No GCs detected
2020-01-24 02:48:38,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2081b78aae675,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 143 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-24 02:48:38,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-24 03:54:32,136 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-24 07:18:30,160 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13726ms
No GCs detected
2020-01-24 17:44:01,431 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8660ms
No GCs detected
2020-01-24 18:38:31,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x21bc09ce1ce79,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 26 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-24 18:38:31,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-24 19:37:40,073 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-24 23:58:48,802 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1935ms
No GCs detected
2020-01-25 02:23:37,185 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11462ms
No GCs detected
2020-01-25 02:40:14,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x22f65c12a1369,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 106 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-25 02:40:14,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-25 03:39:23,318 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-25 08:11:03,048 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9233ms
No GCs detected
2020-01-25 19:25:09,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2430ae5de3f65,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-25 19:25:09,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-25 22:28:42,793 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-25 23:28:39,532 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11729ms
No GCs detected
2020-01-26 00:41:07,761 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8157ms
No GCs detected
2020-01-26 04:42:24,737 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6298ms
No GCs detected
2020-01-26 08:43:42,246 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9433ms
No GCs detected
2020-01-26 19:43:41,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x256b009ad85b9,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 19 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-26 19:43:41,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-26 20:42:50,491 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-27 01:43:16,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x26a552df588a5,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-27 01:43:16,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-27 02:42:25,131 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-27 07:42:51,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x27dfa52343299,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-27 07:42:51,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-27 09:06:52,138 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11322ms
No GCs detected
2020-01-27 09:07:39,080 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5817ms
No GCs detected
2020-01-27 09:07:55,108 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5053ms
No GCs detected
2020-01-27 18:35:57,815 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-28 00:20:16,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2919f76dea521,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 14 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-28 00:20:16,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-28 04:10:17,356 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-28 18:15:39,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a5449ae7696d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-28 18:15:39,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-28 19:14:47,882 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-29 00:15:14,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2b8e9bf6433ad,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-29 00:15:14,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-29 01:14:22,520 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-357219292-172.18.0.2-1578484967825 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-01-29 08:15:35,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2cc8ee3929801,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-01-29 08:15:35,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-357219292-172.18.0.2-1578484967825
2020-01-29 16:08:52,667 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 40633ms
No GCs detected
2020-02-04 23:29:49,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-02-04 23:29:49,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-04 23:29:50,576 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-04 23:29:50,687 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-04 23:29:50,688 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-02-04 23:29:50,697 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-02-04 23:29:50,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2020-02-04 23:29:50,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-02-04 23:29:50,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-02-04 23:29:50,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-02-04 23:29:50,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-02-04 23:29:50,978 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-04 23:29:50,998 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-02-04 23:29:51,025 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-02-04 23:29:51,043 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-04 23:29:51,046 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-02-04 23:29:51,047 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-04 23:29:51,049 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-04 23:29:51,078 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 38941
2020-02-04 23:29:51,079 INFO org.mortbay.log: jetty-6.1.26
2020-02-04 23:29:51,789 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:38941
2020-02-04 23:29:52,089 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-02-04 23:29:52,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-02-04 23:29:52,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-02-04 23:29:52,263 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-02-04 23:29:52,304 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-02-04 23:29:52,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-02-04 23:29:52,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-02-04 23:29:52,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-02-04 23:29:52,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-02-04 23:29:52,452 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-02-04 23:29:52,453 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-02-04 23:29:53,365 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 67@slave1
2020-02-04 23:29:53,372 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1169086459-172.18.0.2-1580830175855
2020-02-04 23:29:53,373 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-04 23:29:53,491 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1169086459-172.18.0.2-1580830175855
2020-02-04 23:29:53,492 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1169086459-172.18.0.2-1580830175855
2020-02-04 23:29:53,503 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1169086459-172.18.0.2-1580830175855 is not formatted for BP-1169086459-172.18.0.2-1580830175855
2020-02-04 23:29:53,504 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-04 23:29:53,505 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1169086459-172.18.0.2-1580830175855 directory /tmp/hadoop/dfs/data/current/BP-1169086459-172.18.0.2-1580830175855/current
2020-02-04 23:29:53,508 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-02-04 23:29:53,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=347583735;bpid=BP-1169086459-172.18.0.2-1580830175855;lv=-56;nsInfo=lv=-63;cid=CID-23d1b847-449c-4728-bbbd-c5eee3b535b7;nsid=347583735;c=0;bpid=BP-1169086459-172.18.0.2-1580830175855;dnuuid=null
2020-02-04 23:29:53,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 1bd7a911-9234-49a6-a7d2-c474c265ae26
2020-02-04 23:29:53,622 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-8c41497f-28fb-491d-9941-a14c452d2b3f
2020-02-04 23:29:53,623 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-02-04 23:29:53,633 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-02-04 23:29:53,634 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1169086459-172.18.0.2-1580830175855
2020-02-04 23:29:53,636 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1169086459-172.18.0.2-1580830175855 on volume /tmp/hadoop/dfs/data/current...
2020-02-04 23:29:53,744 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1169086459-172.18.0.2-1580830175855 on /tmp/hadoop/dfs/data/current: 108ms
2020-02-04 23:29:53,745 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1169086459-172.18.0.2-1580830175855: 110ms
2020-02-04 23:29:53,747 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1169086459-172.18.0.2-1580830175855 on volume /tmp/hadoop/dfs/data/current...
2020-02-04 23:29:53,748 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1169086459-172.18.0.2-1580830175855 on volume /tmp/hadoop/dfs/data/current: 1ms
2020-02-04 23:29:53,748 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 2ms
2020-02-04 23:29:53,977 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1169086459-172.18.0.2-1580830175855 on volume /tmp/hadoop/dfs/data
2020-02-04 23:29:53,985 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8c41497f-28fb-491d-9941-a14c452d2b3f): finished scanning block pool BP-1169086459-172.18.0.2-1580830175855
2020-02-04 23:29:53,999 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1580842742999 with interval 21600000
2020-02-04 23:29:54,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1169086459-172.18.0.2-1580830175855 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-02-04 23:29:54,094 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8c41497f-28fb-491d-9941-a14c452d2b3f): no suitable block pools found to scan.  Waiting 1814399882 ms.
2020-02-04 23:29:54,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1169086459-172.18.0.2-1580830175855 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-02-04 23:29:54,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-02-04 23:29:54,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1169086459-172.18.0.2-1580830175855 (Datanode Uuid 1bd7a911-9234-49a6-a7d2-c474c265ae26) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-02-04 23:29:54,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1169086459-172.18.0.2-1580830175855 (Datanode Uuid 1bd7a911-9234-49a6-a7d2-c474c265ae26) service to master/172.18.0.2:54310
2020-02-04 23:29:54,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x3ded6fce550,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 95 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-04 23:29:54,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1169086459-172.18.0.2-1580830175855
2020-02-04 23:31:21,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1169086459-172.18.0.2-1580830175855:blk_1073741825_1001 src: /172.18.0.2:52112 dest: /172.18.0.3:50010
2020-02-04 23:31:21,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:52112, dest: /172.18.0.3:50010, bytes: 524288, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_620604982_1, offset: 0, srvID: 1bd7a911-9234-49a6-a7d2-c474c265ae26, blockid: BP-1169086459-172.18.0.2-1580830175855:blk_1073741825_1001, duration: 172592109
2020-02-04 23:31:21,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1169086459-172.18.0.2-1580830175855:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-02-04 23:36:33,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-02-04 23:36:33,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-04 23:36:35,682 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-04 23:36:35,883 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-04 23:36:35,884 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-02-04 23:36:35,899 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-02-04 23:36:35,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2020-02-04 23:36:35,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-02-04 23:36:36,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-02-04 23:36:36,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-02-04 23:36:36,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-02-04 23:36:36,355 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-04 23:36:36,384 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-02-04 23:36:36,408 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-02-04 23:36:36,437 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-04 23:36:36,444 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-02-04 23:36:36,445 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-04 23:36:36,446 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-04 23:36:36,504 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40199
2020-02-04 23:36:36,506 INFO org.mortbay.log: jetty-6.1.26
2020-02-04 23:36:37,455 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40199
2020-02-04 23:36:37,793 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-02-04 23:36:37,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-02-04 23:36:37,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-02-04 23:36:38,046 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-02-04 23:36:38,089 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-02-04 23:36:38,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-02-04 23:36:38,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-02-04 23:36:38,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-02-04 23:36:38,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-02-04 23:36:38,276 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-02-04 23:36:38,278 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-02-04 23:36:39,432 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 68@slave1
2020-02-04 23:36:39,437 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1725807159-172.18.0.2-1580830580814
2020-02-04 23:36:39,438 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-04 23:36:39,643 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1725807159-172.18.0.2-1580830580814
2020-02-04 23:36:39,644 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1725807159-172.18.0.2-1580830580814
2020-02-04 23:36:39,646 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1725807159-172.18.0.2-1580830580814 is not formatted for BP-1725807159-172.18.0.2-1580830580814
2020-02-04 23:36:39,647 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-04 23:36:39,648 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1725807159-172.18.0.2-1580830580814 directory /tmp/hadoop/dfs/data/current/BP-1725807159-172.18.0.2-1580830580814/current
2020-02-04 23:36:39,651 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-02-04 23:36:39,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=439303543;bpid=BP-1725807159-172.18.0.2-1580830580814;lv=-56;nsInfo=lv=-63;cid=CID-00a4f34f-3c65-433e-9acd-430f9e878a24;nsid=439303543;c=0;bpid=BP-1725807159-172.18.0.2-1580830580814;dnuuid=null
2020-02-04 23:36:39,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID eaf27f4f-1a08-4e79-902e-063c311b77d3
2020-02-04 23:36:39,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-966e919b-0d15-41ce-a154-23173172d6f6
2020-02-04 23:36:39,868 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-02-04 23:36:39,888 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-02-04 23:36:39,890 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1725807159-172.18.0.2-1580830580814
2020-02-04 23:36:39,894 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1725807159-172.18.0.2-1580830580814 on volume /tmp/hadoop/dfs/data/current...
2020-02-04 23:36:40,033 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1725807159-172.18.0.2-1580830580814 on /tmp/hadoop/dfs/data/current: 138ms
2020-02-04 23:36:40,035 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1725807159-172.18.0.2-1580830580814: 145ms
2020-02-04 23:36:40,037 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1725807159-172.18.0.2-1580830580814 on volume /tmp/hadoop/dfs/data/current...
2020-02-04 23:36:40,038 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1725807159-172.18.0.2-1580830580814 on volume /tmp/hadoop/dfs/data/current: 1ms
2020-02-04 23:36:40,039 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 4ms
2020-02-04 23:36:40,587 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1725807159-172.18.0.2-1580830580814 on volume /tmp/hadoop/dfs/data
2020-02-04 23:36:40,597 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-966e919b-0d15-41ce-a154-23173172d6f6): finished scanning block pool BP-1725807159-172.18.0.2-1580830580814
2020-02-04 23:36:40,599 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1580835892599 with interval 21600000
2020-02-04 23:36:40,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1725807159-172.18.0.2-1580830580814 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-02-04 23:36:40,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1725807159-172.18.0.2-1580830580814 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-02-04 23:36:40,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-02-04 23:36:41,056 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-966e919b-0d15-41ce-a154-23173172d6f6): no suitable block pools found to scan.  Waiting 1814399531 ms.
2020-02-04 23:36:41,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1725807159-172.18.0.2-1580830580814 (Datanode Uuid eaf27f4f-1a08-4e79-902e-063c311b77d3) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-02-04 23:36:41,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1725807159-172.18.0.2-1580830580814 (Datanode Uuid eaf27f4f-1a08-4e79-902e-063c311b77d3) service to master/172.18.0.2:54310
2020-02-04 23:36:41,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x43d9f2e102d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 12 msec to generate and 117 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-04 23:36:41,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1725807159-172.18.0.2-1580830580814
2020-02-05 01:03:15,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-02-05 01:03:15,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-05 01:03:17,448 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-05 01:03:17,719 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-05 01:03:17,719 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-02-05 01:03:17,734 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-02-05 01:03:17,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2020-02-05 01:03:17,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-02-05 01:03:17,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-02-05 01:03:17,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-02-05 01:03:17,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-02-05 01:03:18,201 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-05 01:03:18,232 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-02-05 01:03:18,255 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-02-05 01:03:18,285 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-05 01:03:18,295 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-02-05 01:03:18,296 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-05 01:03:18,297 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-05 01:03:18,359 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46385
2020-02-05 01:03:18,360 INFO org.mortbay.log: jetty-6.1.26
2020-02-05 01:03:19,350 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46385
2020-02-05 01:03:19,734 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-02-05 01:03:19,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-02-05 01:03:19,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-02-05 01:03:19,961 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-02-05 01:03:20,014 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-02-05 01:03:20,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-02-05 01:03:20,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-02-05 01:03:20,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-02-05 01:03:20,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-02-05 01:03:20,231 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-02-05 01:03:20,244 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-02-05 01:03:21,272 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 70@slave1
2020-02-05 01:03:21,287 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-777553246-172.18.0.2-1580835783055
2020-02-05 01:03:21,287 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-05 01:03:21,436 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-777553246-172.18.0.2-1580835783055
2020-02-05 01:03:21,437 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-777553246-172.18.0.2-1580835783055
2020-02-05 01:03:21,442 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-777553246-172.18.0.2-1580835783055 is not formatted for BP-777553246-172.18.0.2-1580835783055
2020-02-05 01:03:21,443 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-05 01:03:21,444 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-777553246-172.18.0.2-1580835783055 directory /tmp/hadoop/dfs/data/current/BP-777553246-172.18.0.2-1580835783055/current
2020-02-05 01:03:21,447 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-02-05 01:03:21,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=735948749;bpid=BP-777553246-172.18.0.2-1580835783055;lv=-56;nsInfo=lv=-63;cid=CID-464cb930-5507-4ee4-ae8d-9a0d636c3a06;nsid=735948749;c=0;bpid=BP-777553246-172.18.0.2-1580835783055;dnuuid=null
2020-02-05 01:03:21,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID cb96bced-43ba-4b34-840b-4404ad50faa5
2020-02-05 01:03:21,588 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-032d6000-087c-41ed-857e-e1a6c9280258
2020-02-05 01:03:21,589 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-02-05 01:03:21,600 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-02-05 01:03:21,601 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-777553246-172.18.0.2-1580835783055
2020-02-05 01:03:21,604 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-777553246-172.18.0.2-1580835783055 on volume /tmp/hadoop/dfs/data/current...
2020-02-05 01:03:21,724 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-777553246-172.18.0.2-1580835783055 on /tmp/hadoop/dfs/data/current: 119ms
2020-02-05 01:03:21,725 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-777553246-172.18.0.2-1580835783055: 123ms
2020-02-05 01:03:21,727 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-777553246-172.18.0.2-1580835783055 on volume /tmp/hadoop/dfs/data/current...
2020-02-05 01:03:21,728 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-777553246-172.18.0.2-1580835783055 on volume /tmp/hadoop/dfs/data/current: 0ms
2020-02-05 01:03:21,729 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 3ms
2020-02-05 01:03:22,020 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-777553246-172.18.0.2-1580835783055 on volume /tmp/hadoop/dfs/data
2020-02-05 01:03:22,027 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-032d6000-087c-41ed-857e-e1a6c9280258): finished scanning block pool BP-777553246-172.18.0.2-1580835783055
2020-02-05 01:03:22,057 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1580846587057 with interval 21600000
2020-02-05 01:03:22,080 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-777553246-172.18.0.2-1580835783055 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-02-05 01:03:22,160 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-032d6000-087c-41ed-857e-e1a6c9280258): no suitable block pools found to scan.  Waiting 1814399860 ms.
2020-02-05 01:03:22,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-777553246-172.18.0.2-1580835783055 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-02-05 01:03:22,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-02-05 01:03:22,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-777553246-172.18.0.2-1580835783055 (Datanode Uuid cb96bced-43ba-4b34-840b-4404ad50faa5) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-02-05 01:03:22,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-777553246-172.18.0.2-1580835783055 (Datanode Uuid cb96bced-43ba-4b34-840b-4404ad50faa5) service to master/172.18.0.2:54310
2020-02-05 01:03:22,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x8f98d39ae57,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 117 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-05 01:03:22,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-777553246-172.18.0.2-1580835783055
2020-02-05 01:16:13,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-02-05 01:16:13,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-05 01:16:15,835 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-05 01:16:16,019 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-05 01:16:16,020 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-02-05 01:16:16,031 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-02-05 01:16:16,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2020-02-05 01:16:16,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-02-05 01:16:16,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-02-05 01:16:16,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-02-05 01:16:16,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-02-05 01:16:16,509 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-05 01:16:16,535 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-02-05 01:16:16,554 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-02-05 01:16:16,580 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-05 01:16:16,584 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-02-05 01:16:16,585 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-05 01:16:16,587 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-05 01:16:16,634 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 32897
2020-02-05 01:16:16,637 INFO org.mortbay.log: jetty-6.1.26
2020-02-05 01:16:17,405 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:32897
2020-02-05 01:16:17,776 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-02-05 01:16:17,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-02-05 01:16:17,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-02-05 01:16:17,997 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-02-05 01:16:18,074 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-02-05 01:16:18,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-02-05 01:16:18,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-02-05 01:16:18,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-02-05 01:16:18,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-02-05 01:16:18,262 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-02-05 01:16:18,254 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-02-05 01:16:19,143 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 70@slave1
2020-02-05 01:16:19,147 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1474470855-172.18.0.2-1580836560765
2020-02-05 01:16:19,148 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-05 01:16:19,301 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1474470855-172.18.0.2-1580836560765
2020-02-05 01:16:19,302 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1474470855-172.18.0.2-1580836560765
2020-02-05 01:16:19,305 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1474470855-172.18.0.2-1580836560765 is not formatted for BP-1474470855-172.18.0.2-1580836560765
2020-02-05 01:16:19,306 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-05 01:16:19,306 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1474470855-172.18.0.2-1580836560765 directory /tmp/hadoop/dfs/data/current/BP-1474470855-172.18.0.2-1580836560765/current
2020-02-05 01:16:19,309 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-02-05 01:16:19,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=416019751;bpid=BP-1474470855-172.18.0.2-1580836560765;lv=-56;nsInfo=lv=-63;cid=CID-17a7ef30-ba6d-4ec4-8ab1-e50deff6ae90;nsid=416019751;c=0;bpid=BP-1474470855-172.18.0.2-1580836560765;dnuuid=null
2020-02-05 01:16:19,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 28dcbd35-02ab-4851-a6bb-ffb42800d462
2020-02-05 01:16:19,574 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-ada82919-5d2f-4e02-9e90-e030f7a4d661
2020-02-05 01:16:19,575 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-02-05 01:16:19,598 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-02-05 01:16:19,599 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1474470855-172.18.0.2-1580836560765
2020-02-05 01:16:19,610 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1474470855-172.18.0.2-1580836560765 on volume /tmp/hadoop/dfs/data/current...
2020-02-05 01:16:19,758 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1474470855-172.18.0.2-1580836560765 on /tmp/hadoop/dfs/data/current: 146ms
2020-02-05 01:16:19,759 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1474470855-172.18.0.2-1580836560765: 159ms
2020-02-05 01:16:19,760 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1474470855-172.18.0.2-1580836560765 on volume /tmp/hadoop/dfs/data/current...
2020-02-05 01:16:19,761 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1474470855-172.18.0.2-1580836560765 on volume /tmp/hadoop/dfs/data/current: 0ms
2020-02-05 01:16:19,762 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 2ms
2020-02-05 01:16:20,116 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1474470855-172.18.0.2-1580836560765 on volume /tmp/hadoop/dfs/data
2020-02-05 01:16:20,127 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-ada82919-5d2f-4e02-9e90-e030f7a4d661): finished scanning block pool BP-1474470855-172.18.0.2-1580836560765
2020-02-05 01:16:20,155 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1580844356155 with interval 21600000
2020-02-05 01:16:20,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1474470855-172.18.0.2-1580836560765 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-02-05 01:16:20,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1474470855-172.18.0.2-1580836560765 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-02-05 01:16:20,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-02-05 01:16:20,370 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-ada82919-5d2f-4e02-9e90-e030f7a4d661): no suitable block pools found to scan.  Waiting 1814399746 ms.
2020-02-05 01:16:20,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1474470855-172.18.0.2-1580836560765 (Datanode Uuid 28dcbd35-02ab-4851-a6bb-ffb42800d462) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-02-05 01:16:20,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1474470855-172.18.0.2-1580836560765 (Datanode Uuid 28dcbd35-02ab-4851-a6bb-ffb42800d462) service to master/172.18.0.2:54310
2020-02-05 01:16:20,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x9aed9b94488,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 145 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-05 01:16:20,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1474470855-172.18.0.2-1580836560765
2020-02-05 01:20:20,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-02-05 01:20:20,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-05 01:20:22,503 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-05 01:20:22,695 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-05 01:20:22,695 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-02-05 01:20:22,708 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-02-05 01:20:22,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2020-02-05 01:20:22,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-02-05 01:20:22,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-02-05 01:20:22,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-02-05 01:20:22,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-02-05 01:20:23,171 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-05 01:20:23,204 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-02-05 01:20:23,230 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-02-05 01:20:23,258 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-05 01:20:23,265 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-02-05 01:20:23,267 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-05 01:20:23,269 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-05 01:20:23,331 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46229
2020-02-05 01:20:23,334 INFO org.mortbay.log: jetty-6.1.26
2020-02-05 01:20:24,234 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46229
2020-02-05 01:20:24,581 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-02-05 01:20:24,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-02-05 01:20:24,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-02-05 01:20:24,842 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-02-05 01:20:24,896 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-02-05 01:20:24,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-02-05 01:20:25,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-02-05 01:20:25,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-02-05 01:20:25,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-02-05 01:20:25,100 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-02-05 01:20:25,102 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-02-05 01:20:26,174 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 72@slave1
2020-02-05 01:20:26,177 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-518620581-172.18.0.2-1580836808020
2020-02-05 01:20:26,178 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-05 01:20:26,318 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-518620581-172.18.0.2-1580836808020
2020-02-05 01:20:26,319 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-518620581-172.18.0.2-1580836808020
2020-02-05 01:20:26,322 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-518620581-172.18.0.2-1580836808020 is not formatted for BP-518620581-172.18.0.2-1580836808020
2020-02-05 01:20:26,324 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-05 01:20:26,324 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-518620581-172.18.0.2-1580836808020 directory /tmp/hadoop/dfs/data/current/BP-518620581-172.18.0.2-1580836808020/current
2020-02-05 01:20:26,328 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-02-05 01:20:26,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1975424816;bpid=BP-518620581-172.18.0.2-1580836808020;lv=-56;nsInfo=lv=-63;cid=CID-5f3fd106-baa9-4b10-9d23-5d0896103f89;nsid=1975424816;c=0;bpid=BP-518620581-172.18.0.2-1580836808020;dnuuid=null
2020-02-05 01:20:26,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 97ea8544-d62c-4c0f-a9aa-42d7166b201c
2020-02-05 01:20:26,473 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-f21a01e3-55a2-4c77-8875-9e250f277f20
2020-02-05 01:20:26,474 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-02-05 01:20:26,515 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-02-05 01:20:26,516 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-518620581-172.18.0.2-1580836808020
2020-02-05 01:20:26,527 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-518620581-172.18.0.2-1580836808020 on volume /tmp/hadoop/dfs/data/current...
2020-02-05 01:20:26,694 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-518620581-172.18.0.2-1580836808020 on /tmp/hadoop/dfs/data/current: 164ms
2020-02-05 01:20:26,695 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-518620581-172.18.0.2-1580836808020: 177ms
2020-02-05 01:20:26,696 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-518620581-172.18.0.2-1580836808020 on volume /tmp/hadoop/dfs/data/current...
2020-02-05 01:20:26,697 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-518620581-172.18.0.2-1580836808020 on volume /tmp/hadoop/dfs/data/current: 1ms
2020-02-05 01:20:26,698 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 2ms
2020-02-05 01:20:27,013 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-518620581-172.18.0.2-1580836808020 on volume /tmp/hadoop/dfs/data
2020-02-05 01:20:27,022 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-f21a01e3-55a2-4c77-8875-9e250f277f20): finished scanning block pool BP-518620581-172.18.0.2-1580836808020
2020-02-05 01:20:27,045 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1580841254045 with interval 21600000
2020-02-05 01:20:27,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-518620581-172.18.0.2-1580836808020 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-02-05 01:20:27,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-518620581-172.18.0.2-1580836808020 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-02-05 01:20:27,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-02-05 01:20:27,287 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-f21a01e3-55a2-4c77-8875-9e250f277f20): no suitable block pools found to scan.  Waiting 1814399726 ms.
2020-02-05 01:20:27,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-518620581-172.18.0.2-1580836808020 (Datanode Uuid 97ea8544-d62c-4c0f-a9aa-42d7166b201c) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-02-05 01:20:27,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-518620581-172.18.0.2-1580836808020 (Datanode Uuid 97ea8544-d62c-4c0f-a9aa-42d7166b201c) service to master/172.18.0.2:54310
2020-02-05 01:20:27,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x9e85db3c38d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 11 msec to generate and 117 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-05 01:20:27,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-518620581-172.18.0.2-1580836808020
2020-02-05 04:03:18,501 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 22289ms
No GCs detected
2020-02-05 04:41:55,482 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-518620581-172.18.0.2-1580836808020 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-02-05 05:10:10,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xf7a25b16fc4,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 38 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-05 05:10:10,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-518620581-172.18.0.2-1580836808020
2020-02-05 10:58:07,936 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 17641ms
No GCs detected
2020-02-05 10:58:44,220 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10431ms
No GCs detected
2020-02-05 18:02:28,929 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-518620581-172.18.0.2-1580836808020 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-02-05 18:30:43,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x231f4a5ddd54,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-05 18:30:43,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-518620581-172.18.0.2-1580836808020
2020-02-06 17:52:40,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-02-06 17:52:40,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-06 17:52:42,179 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-06 17:52:42,357 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-06 17:52:42,358 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-02-06 17:52:42,371 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-02-06 17:52:42,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2020-02-06 17:52:42,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-02-06 17:52:42,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-02-06 17:52:42,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-02-06 17:52:42,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-02-06 17:52:42,816 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-06 17:52:42,835 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-02-06 17:52:42,856 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-02-06 17:52:42,879 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-06 17:52:42,888 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-02-06 17:52:42,889 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-06 17:52:42,890 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-06 17:52:42,921 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34803
2020-02-06 17:52:42,923 INFO org.mortbay.log: jetty-6.1.26
2020-02-06 17:52:43,830 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:34803
2020-02-06 17:52:44,194 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-02-06 17:52:44,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-02-06 17:52:44,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-02-06 17:52:44,515 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-02-06 17:52:44,575 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-02-06 17:52:44,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-02-06 17:52:44,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-02-06 17:52:44,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-02-06 17:52:44,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-02-06 17:52:44,781 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-02-06 17:52:44,791 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-02-06 17:52:46,789 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 70@slave1
2020-02-06 17:52:46,794 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1913368944-172.18.0.2-1580982745626
2020-02-06 17:52:46,795 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-06 17:52:47,048 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1913368944-172.18.0.2-1580982745626
2020-02-06 17:52:47,049 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1913368944-172.18.0.2-1580982745626
2020-02-06 17:52:47,054 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1913368944-172.18.0.2-1580982745626 is not formatted for BP-1913368944-172.18.0.2-1580982745626
2020-02-06 17:52:47,054 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-02-06 17:52:47,055 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1913368944-172.18.0.2-1580982745626 directory /tmp/hadoop/dfs/data/current/BP-1913368944-172.18.0.2-1580982745626/current
2020-02-06 17:52:47,060 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-02-06 17:52:47,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1505753509;bpid=BP-1913368944-172.18.0.2-1580982745626;lv=-56;nsInfo=lv=-63;cid=CID-71db67d9-2ed5-4c6c-b2ce-c2ff4951615a;nsid=1505753509;c=0;bpid=BP-1913368944-172.18.0.2-1580982745626;dnuuid=null
2020-02-06 17:52:47,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID a3d59853-0811-431e-8360-cac27bcb9a29
2020-02-06 17:52:47,263 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-3695536c-1c44-4ed2-bc54-4266d2aa94e2
2020-02-06 17:52:47,264 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-02-06 17:52:47,273 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-02-06 17:52:47,274 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1913368944-172.18.0.2-1580982745626
2020-02-06 17:52:47,276 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1913368944-172.18.0.2-1580982745626 on volume /tmp/hadoop/dfs/data/current...
2020-02-06 17:52:47,397 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1913368944-172.18.0.2-1580982745626 on /tmp/hadoop/dfs/data/current: 120ms
2020-02-06 17:52:47,398 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1913368944-172.18.0.2-1580982745626: 123ms
2020-02-06 17:52:47,400 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1913368944-172.18.0.2-1580982745626 on volume /tmp/hadoop/dfs/data/current...
2020-02-06 17:52:47,401 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1913368944-172.18.0.2-1580982745626 on volume /tmp/hadoop/dfs/data/current: 1ms
2020-02-06 17:52:47,402 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 2ms
2020-02-06 17:52:48,405 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1913368944-172.18.0.2-1580982745626 on volume /tmp/hadoop/dfs/data
2020-02-06 17:52:48,419 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-3695536c-1c44-4ed2-bc54-4266d2aa94e2): finished scanning block pool BP-1913368944-172.18.0.2-1580982745626
2020-02-06 17:52:48,459 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1580986830459 with interval 21600000
2020-02-06 17:52:48,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1913368944-172.18.0.2-1580982745626 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-02-06 17:52:48,624 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-3695536c-1c44-4ed2-bc54-4266d2aa94e2): no suitable block pools found to scan.  Waiting 1814399780 ms.
2020-02-06 17:52:48,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1913368944-172.18.0.2-1580982745626 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-02-06 17:52:48,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-02-06 17:52:49,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1913368944-172.18.0.2-1580982745626 (Datanode Uuid a3d59853-0811-431e-8360-cac27bcb9a29) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-02-06 17:52:49,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1913368944-172.18.0.2-1580982745626 (Datanode Uuid a3d59853-0811-431e-8360-cac27bcb9a29) service to master/172.18.0.2:54310
2020-02-06 17:52:49,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x19a3e37a76f,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 24 msec to generate and 456 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-06 17:52:49,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1913368944-172.18.0.2-1580982745626
2020-02-06 20:39:24,096 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11738ms
No GCs detected
2020-02-06 20:43:38,211 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1913368944-172.18.0.2-1580982745626 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-02-06 23:26:52,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xe370948066d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-02-06 23:26:52,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1913368944-172.18.0.2-1580982745626
